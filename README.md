# è¯­ä¹‰æ‹“æ‰‘åˆ†æé¡¹ç›® (Semantic Topology Analysis)

ç”¨äºåˆ†ææ–‡å­¦ä½œå“è¯­ä¹‰æ‹“æ‰‘ç»“æ„çš„å®Œæ•´å·¥å…·é“¾ï¼Œé€šè¿‡BERTåµŒå…¥ã€æ‹“æ‰‘æ•°æ®åˆ†æï¼ˆTDAï¼‰å’ŒMapperå¯è§†åŒ–æ¥å‘ç°æ–‡æœ¬çš„è¯­ä¹‰ç»“æ„ç‰¹å¾ã€‚

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®ç°äº†ä¸€å¥—å®Œæ•´çš„æ— ç›‘ç£è¯­ä¹‰æ‹“æ‰‘åˆ†ææ¡†æ¶ï¼Œç”¨äºä»æ–‡æœ¬ä¸­å‘ç°è¯­ä¹‰ç»“æ„ã€‚é¡¹ç›®åŸºäºä»¥ä¸‹å‡è®¾ï¼š

- **æµå½¢å‡è®¾**ï¼šè‡ªç„¶è¯­è¨€è¯­ä¹‰åˆ†å¸ƒåµŒå…¥äºé«˜ç»´æµå½¢ï¼Œå‡ ä½•ç»“æ„ç¼–ç è¯­ä¹‰ä¿¡æ¯
- **æ— ç›‘ç£æ–¹æ³•**ï¼šä¸é¢„è®¾è¯è¡¨ï¼Œä½¿æ–‡æœ¬çš„è¯­ä¹‰ç»“æ„ä»¥æ•°å­¦å½¢å¼è‡ªå‘æ¶Œç°

### æŠ€æœ¯è·¯çº¿

```
å…¨é‡ä¸Šä¸‹æ–‡åµŒå…¥ â†’ è¯­ä¹‰ç‚¹äº‘ â†’ Witness å¤å½¢ â†’ æŒç»­åŒè°ƒï¼ˆÎ²1ï¼‰ â†’ 
åŒè°ƒç”Ÿæˆå…ƒé€†å‘æ˜ å°„ â†’ Mapper éª¨æ¶å›¾
```

## åŠŸèƒ½ç‰¹æ€§

- ğŸ“„ **å¤šæ ¼å¼æ–‡æœ¬æå–**ï¼šæ”¯æŒPDFã€EPUBã€TXTï¼Œå¸¦OCRå›é€€æ”¯æŒ
- ğŸ”¤ **NLPé¢„å¤„ç†**ï¼šè¯æ€§è¿‡æ»¤ã€åœç”¨è¯è¿‡æ»¤ã€è¯é¢‘ç»Ÿè®¡
- ğŸ§  **ä¸Šä¸‹æ–‡æ„ŸçŸ¥åµŒå…¥**ï¼šåŸºäºBERTçš„è¯­ä¹‰åµŒå…¥ç”Ÿæˆ
- ğŸ”¬ **æ‹“æ‰‘æ•°æ®åˆ†æ**ï¼šæŒç»­åŒè°ƒï¼ˆÎ²1æ¡ç ï¼‰ã€è¾¹ç•Œè¯æå–
- ğŸ“Š **äº¤äº’å¼å¯è§†åŒ–**ï¼šMapperéª¨æ¶å›¾ï¼ˆHTMLï¼‰ã€UMAPé™ç»´

## å®‰è£…æŒ‡å—

### ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- 8GB+ RAMï¼ˆæ¨è16GBç”¨äºå¤§å‹æ–‡æœ¬ï¼‰
- GPUï¼ˆå¯é€‰ï¼Œç”¨äºåŠ é€ŸBERTåµŒå…¥ï¼‰

### 1. å…‹éš†ä»“åº“

```bash
git clone <repository-url>
cd Semantic-Topology
```

### 2. å®‰è£…Pythonä¾èµ–

```bash
pip install -r requirements.txt
```

### 3. å®‰è£…Spacyè¯­è¨€æ¨¡å‹

```bash
python -m spacy download en_core_web_sm
```

### 4. ï¼ˆå¯é€‰ï¼‰å®‰è£…Tesseract OCR

å¦‚æœè¦å¤„ç†æ‰«æç‰ˆPDFï¼Œéœ€è¦å®‰è£…Tesseract OCRï¼š

**Windows:**
- ä¸‹è½½å®‰è£…ç¨‹åºï¼šhttps://github.com/UB-Mannheim/tesseract/wiki
- å®‰è£…åï¼Œåœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®è·¯å¾„ï¼š`config/default_config.yaml`

**Linux:**
```bash
sudo apt-get install tesseract-ocr tesseract-ocr-eng tesseract-ocr-chi-sim
```

**macOS:**
```bash
brew install tesseract
```

## é…ç½®è¯´æ˜

é…ç½®æ–‡ä»¶ä½äº `config/default_config.yaml`ï¼Œä¸»è¦é…ç½®é¡¹åŒ…æ‹¬ï¼š

### æ•°æ®è·¯å¾„

```yaml
data:
  input_dir: "artifacts/raw_texts"      # åŸå§‹æ–‡ä»¶ç›®å½•
  texts_dir: "artifacts/texts"          # æå–çš„æ–‡æœ¬ç›®å½•
  embeddings_dir: "artifacts/embeddings" # åµŒå…¥æ–‡ä»¶ç›®å½•
  tda_dir: "artifacts/tda"              # TDAç»“æœç›®å½•
  mapper_dir: "artifacts/mapper"        # Mapperå¯è§†åŒ–ç›®å½•
  results_dir: "artifacts/results"      # åˆ†æç»“æœç›®å½•
```

### NLPå¤„ç†

```yaml
nlp:
  model: "bert-base-cased"              # BERTæ¨¡å‹åç§°
  spacy_model: "en_core_web_sm"         # Spacyæ¨¡å‹
  keep_pos: ["NOUN", "PROPN", "ADJ", "VERB"]  # ä¿ç•™çš„è¯æ€§
  min_freq: 5                           # æœ€å°è¯é¢‘
```

### æ‹“æ‰‘æ•°æ®åˆ†æ

```yaml
tda:
  landmark_strategy: "kmeans"           # åœ°æ ‡é€‰æ‹©ç­–ç•¥: 'kmeans' æˆ– 'maxmin'
  n_landmarks: 512                      # åœ°æ ‡æ•°é‡
  persistence_threshold: 0.05           # æŒä¹…åº¦é˜ˆå€¼
```

### å¯è§†åŒ–

```yaml
visualization:
  mapper_neighbors: 15                  # Mapperé‚»å±…æ•°
  mapper_overlap: 0.5                   # Mapperé‡å æ¯”ä¾‹
  umap_n_neighbors: 15                  # UMAPé‚»å±…æ•°
  umap_min_dist: 0.1                    # UMAPæœ€å°è·ç¦»
```

### ç¯å¢ƒå˜é‡è¦†ç›–

æ‰€æœ‰é…ç½®é¡¹éƒ½å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼š

```bash
export NLP_MODEL="prajjwal1/bert-tiny"  # ä½¿ç”¨æ›´å°çš„æ¨¡å‹åŠ é€Ÿ
export TDA_N_LANDMARKS=256              # å‡å°‘åœ°æ ‡æ•°ä»¥åŠ å¿«è®¡ç®—
export FREQ_MIN=1                       # é™ä½è¯é¢‘é˜ˆå€¼
```

## ä½¿ç”¨æ–¹æ³•

### å®Œæ•´æµæ°´çº¿

è¿è¡Œå®Œæ•´çš„åˆ†ææµæ°´çº¿ï¼ˆæ–‡æœ¬æå– â†’ åµŒå…¥ç”Ÿæˆ â†’ TDAåˆ†æ â†’ å¯è§†åŒ–ï¼‰ï¼š

```bash
python run_pipeline.py
```

### å•ç‹¬è¿è¡Œå„æ­¥éª¤

#### 1. æ–‡æœ¬æå–

```python
from src.data_loader import extract_all
from src.utils import load_config, get_path, get_project_root

config = load_config()
root = get_project_root()
texts_dir = get_path(config, 'data.texts_dir', root)

extracted = extract_all(root, texts_dir, config)
```

#### 2. ç”ŸæˆåµŒå…¥

```python
from src.embedder import embed_text_file
from pathlib import Path

emb_path = embed_text_file(
    Path("artifacts/texts/example.txt"),
    Path("artifacts/embeddings"),
    config
)
```

#### 3. æ‹“æ‰‘æ•°æ®åˆ†æ

```python
from src.topology import analyze

tda_path, cycle_words, metrics = analyze(
    Path("artifacts/embeddings/example_embeddings.npz"),
    Path("artifacts/tda"),
    config
)

birth, death, persistence = metrics
print(f"Î²1æ¡ç : birth={birth:.6f}, death={death:.6f}, persistence={persistence:.6f}")
print(f"è¾¹ç•Œè¯: {cycle_words[:10]}")
```

#### 4. å¯è§†åŒ–

```python
from src.visualizer import visualize

html_path, summary_path = visualize(
    Path("artifacts/embeddings/example_embeddings.npz"),
    Path("artifacts/mapper"),
    config
)
```

### ä½¿ç”¨è„šæœ¬

#### æ‰¹é‡åˆ†æåµŒå…¥æ–‡ä»¶

```bash
python scripts/run_tda_mapper.py
```

#### åˆ†æç‰¹å®šè‹±æ–‡æ–‡ä»¶

```bash
python scripts/analyze_en.py
```

#### æ‰¹é‡å¤„ç†æ–‡æœ¬æ–‡ä»¶

```bash
python scripts/batch_analysis.py
```

#### æŸ¥çœ‹åµŒå…¥æ–‡ä»¶å½¢çŠ¶

```bash
python scripts/report_shapes.py
```

## è¾“å‡ºæ–‡ä»¶è¯´æ˜

### æ–‡æœ¬æ–‡ä»¶

- **ä½ç½®**: `artifacts/texts/*.txt`
- **æ ¼å¼**: çº¯æ–‡æœ¬ï¼ŒUTF-8ç¼–ç 

### åµŒå…¥æ–‡ä»¶

- **ä½ç½®**: `artifacts/embeddings/*_embeddings.npz`
- **æ ¼å¼**: NumPyå‹ç¼©æ–‡ä»¶
- **å†…å®¹**:
  - `X`: åµŒå…¥çŸ©é˜µ (N, d)
  - `labels`: è¯æ ‡ç­¾æ•°ç»„ (N,)

### TDAç»“æœ

- **ä½ç½®**: `artifacts/tda/*_beta1.npy`
- **æ ¼å¼**: NumPyæ–‡ä»¶
- **å†…å®¹**:
  - `dgms`: æ¡ç å›¾
  - `cocycles`: ä½™å¾ªç¯
  - `birth`, `death`, `persistence`: Î²1æ¡ç å‚æ•°
  - `cycle_words`: è¾¹ç•Œè¯åˆ—è¡¨

### å¯è§†åŒ–æ–‡ä»¶

- **HTML**: `artifacts/mapper/*_mapper.html` - äº¤äº’å¼Mapperéª¨æ¶å›¾
- **æ‘˜è¦**: `artifacts/mapper/*_mapper_summary.txt` - èŠ‚ç‚¹å’Œè¿è¾¹ç»Ÿè®¡

### åˆ†ææŠ¥å‘Š

- **ä½ç½®**: `artifacts/results/analysis.md`
- **æ ¼å¼**: Markdown
- **å†…å®¹**: æ‰€æœ‰åˆ†æç»“æœçš„æ±‡æ€»æŠ¥å‘Š

## é¡¹ç›®ç»“æ„

```
Semantic-Topology/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ default_config.yaml      # é…ç½®æ–‡ä»¶
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils.py                 # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ data_loader.py           # æ–‡æœ¬æå–
â”‚   â”œâ”€â”€ nlp_processor.py         # NLPå¤„ç†
â”‚   â”œâ”€â”€ embedder.py              # åµŒå…¥ç”Ÿæˆ
â”‚   â”œâ”€â”€ topology.py              # TDAåˆ†æ
â”‚   â””â”€â”€ visualizer.py            # å¯è§†åŒ–
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ analyze_en.py            # åˆ†æè‹±æ–‡æ–‡ä»¶
â”‚   â”œâ”€â”€ batch_analysis.py        # æ‰¹é‡åˆ†æ
â”‚   â”œâ”€â”€ run_tda_mapper.py        # TDAå’ŒMapperåˆ†æ
â”‚   â””â”€â”€ report_shapes.py         # æŠ¥å‘ŠåµŒå…¥å½¢çŠ¶
â”œâ”€â”€ artifacts/                   # è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ texts/                   # æå–çš„æ–‡æœ¬
â”‚   â”œâ”€â”€ embeddings/              # åµŒå…¥æ–‡ä»¶
â”‚   â”œâ”€â”€ tda/                     # TDAç»“æœ
â”‚   â”œâ”€â”€ mapper/                  # Mapperå¯è§†åŒ–
â”‚   â””â”€â”€ results/                 # åˆ†ææŠ¥å‘Š
â”œâ”€â”€ notebooks/                   # Jupyter notebooks
â”œâ”€â”€ run_pipeline.py              # ä¸»æµæ°´çº¿
â”œâ”€â”€ requirements.txt             # Pythonä¾èµ–
â””â”€â”€ README.md                    # æœ¬æ–‡æ¡£
```

## ç¤ºä¾‹

### åˆ†æå¾·åˆ©æ´›ä½œå“

é¡¹ç›®åŒ…å«äº†åˆ†æDon DeLilloæ™šæœŸä¸‰éƒ¨ä½œå“çš„ç¤ºä¾‹ï¼š

1. **Point Omega (2010)**
2. **Zero K (2016)**
3. **The Silence (2020)**

è¿è¡Œå®Œæ•´æµæ°´çº¿ï¼š

```bash
python run_pipeline.py
```

æŸ¥çœ‹ç»“æœï¼š

```bash
cat artifacts/results/analysis.md
```

æ‰“å¼€å¯è§†åŒ–ï¼š

```bash
# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
open artifacts/mapper/2010_Point_Omega_mapper.html
```

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•åŠ é€ŸåµŒå…¥ç”Ÿæˆï¼Ÿ

A: æœ‰å‡ ç§æ–¹æ³•ï¼š
1. ä½¿ç”¨æ›´å°çš„BERTæ¨¡å‹ï¼ˆå¦‚ `prajjwal1/bert-tiny`ï¼‰
2. è®¾ç½®ç¯å¢ƒå˜é‡ `USE_GPU=false` å¦‚æœGPUå†…å­˜ä¸è¶³
3. å‡å° `batch_size` é…ç½®

### Q: OCRæå–å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

A: 
1. ç¡®ä¿å·²å®‰è£…Tesseract OCR
2. åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æ­£ç¡®çš„ `tesseract_path`
3. æ£€æŸ¥PDFæ˜¯å¦ä¸ºæ‰«æç‰ˆï¼ˆéœ€è¦OCRï¼‰

### Q: å†…å­˜ä¸è¶³é”™è¯¯

A:
1. å‡å°‘åœ°æ ‡æ•°é‡ï¼ˆ`n_landmarks`ï¼‰
2. é™åˆ¶å¤„ç†çš„æœ€å¤§å¥å­æ•°ï¼ˆ`max_sentences`ï¼‰
3. ä½¿ç”¨CPUè€ŒéGPUï¼ˆå‡å°‘GPUå†…å­˜å ç”¨ï¼‰

### Q: å¦‚ä½•è°ƒæ•´è¯é¢‘é˜ˆå€¼ï¼Ÿ

A: ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ `nlp.min_freq`ï¼Œæˆ–è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
```bash
export FREQ_MIN=1  # åŒ…å«æ‰€æœ‰è¯
```

## æŠ€æœ¯æ ˆ

- **æ–‡æœ¬å¤„ç†**: pdfminer.six, ebooklib, pytesseract
- **NLP**: spaCy, transformers
- **æœºå™¨å­¦ä¹ **: scikit-learn, PyTorch
- **æ‹“æ‰‘æ•°æ®åˆ†æ**: ripser
- **å¯è§†åŒ–**: kmapper, umap-learn
- **é…ç½®ç®¡ç†**: PyYAML

## å‚è€ƒæ–‡çŒ®

1. Singh, G., MÃ©moli, F., & Carlsson, G. (2007). Topological Methods for the Analysis of High Dimensional Data Sets and 3D Object Recognition. SODA 2007.

2. Edelsbrunner, H., & Harer, J. (2010). Computational Topology: An Introduction.

3. Chazal, F., Michel, B., & Rieck, B. (2021). An Introduction to Topological Data Analysis: Fundamental and Practical Aspects for Data Scientists.

## è®¸å¯è¯

[æ·»åŠ è®¸å¯è¯ä¿¡æ¯]

## è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## è”ç³»æ–¹å¼

[æ·»åŠ è”ç³»æ–¹å¼]

---

**æ³¨æ„**: æœ¬é¡¹ç›®ä»åœ¨æŒç»­å¼€å‘ä¸­ã€‚å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡Issueåé¦ˆã€‚

